{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5425ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (only needed once)\n",
    "!pip install openai pinecone-client tiktoken --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccca74a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import openai\n",
    "import pinecone\n",
    "import os\n",
    "import tiktoken\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd873f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API keys here\n",
    "openai.api_key = \"sk-REPLACE_WITH_YOUR_OPENAI_KEY\"\n",
    "pinecone.init(\n",
    "    api_key=\"REPLACE_WITH_YOUR_PINECONE_API_KEY\",\n",
    "    environment=\"REPLACE_WITH_YOUR_ENVIRONMENT\"  # e.g., \"gcp-starter\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc2561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your business document (TXT preferred for simplicity)\n",
    "uploaded = files.upload()\n",
    "\n",
    "all_text = \"\"\n",
    "for filename in uploaded:\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        all_text += f.read() + \"\\n\"\n",
    "print(\"✅ Document uploaded and read.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab964d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text into chunks\n",
    "def split_text(text, max_tokens=500, overlap=50):\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoding.encode(text)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = start + max_tokens\n",
    "        chunk = encoding.decode(tokens[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start += max_tokens - overlap\n",
    "    return chunks\n",
    "\n",
    "chunks = split_text(all_text)\n",
    "print(f\"✅ Split into {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00aa19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed text chunks using OpenAI\n",
    "def get_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), 100):\n",
    "        response = openai.Embedding.create(\n",
    "            input=texts[i:i+100],\n",
    "            model=\"text-embedding-3-small\"\n",
    "        )\n",
    "        embeddings.extend([r[\"embedding\"] for r in response[\"data\"]])\n",
    "    return embeddings\n",
    "\n",
    "embeddings = get_embeddings(chunks)\n",
    "print(\"✅ Embeddings created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4c472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pinecone index and store embeddings\n",
    "index_name = \"rag-qa-business\"\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(index_name, dimension=1536, metric=\"cosine\")\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "ids = [f\"chunk-{i}\" for i in range(len(chunks))]\n",
    "to_upsert = list(zip(ids, embeddings, [{\"text\": chunk} for chunk in chunks]))\n",
    "index.upsert(vectors=to_upsert)\n",
    "print(\"✅ Chunks uploaded to Pinecone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d77490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval + Generation (QA Function)\n",
    "def retrieve_chunks(query, top_k=3):\n",
    "    query_embedding = openai.Embedding.create(\n",
    "        input=[query],\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )[\"data\"][0][\"embedding\"]\n",
    "    \n",
    "    results = index.query(vector=query_embedding, top_k=top_k, include_metadata=True)\n",
    "    return [match[\"metadata\"][\"text\"] for match in results[\"matches\"]]\n",
    "\n",
    "def generate_answer(query):\n",
    "    context = \"\\n---\\n\".join(retrieve_chunks(query))\n",
    "    prompt = f\"\"\"You are a helpful business assistant. Use the context below to answer the question.\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a299367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Example Question\n",
    "query = \"What is the refund policy?\"\n",
    "answer = generate_answer(query)\n",
    "print(\"Answer:\", answer)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
